{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MedTextGenerationModels.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ll3091/ANLY-580-01-NLP-Project/blob/master/MedTextGenerationModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "mrB_G9Ab1QR2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# NLP Project: Text Generation Model Training"
      ]
    },
    {
      "metadata": {
        "id": "PtS7V74X1VaL",
        "colab_type": "code",
        "outputId": "517e5a61-8e08-4e7e-d75d-a98a7fbc12d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "cell_type": "code",
      "source": [
        "# source https://github.com/minimaxir/textgenrnn\n",
        "! pip install textgenrnn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting textgenrnn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/f8/f1968b2078a9076f481916fba5d98affa019943e4f5764224ffaeb57b7c7/textgenrnn-1.4.1.tar.gz (1.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.7MB 14.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from textgenrnn) (2.2.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from textgenrnn) (2.8.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from textgenrnn) (0.19.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.5->textgenrnn) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.5->textgenrnn) (1.0.6)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.5->textgenrnn) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.5->textgenrnn) (1.11.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.5->textgenrnn) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.5->textgenrnn) (1.14.6)\n",
            "Building wheels for collected packages: textgenrnn\n",
            "  Running setup.py bdist_wheel for textgenrnn ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/30/96/f7/bc7042ea671bc79455c244af21050a7a32d604fe2f7a44e322\n",
            "Successfully built textgenrnn\n",
            "Installing collected packages: textgenrnn\n",
            "Successfully installed textgenrnn-1.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3QC0MFkv2RJ6",
        "colab_type": "code",
        "outputId": "8dd6b8a5-29f2-4e50-e270-ac3ed6a12272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from textgenrnn import textgenrnn\n",
        "from google.colab import drive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "l-aqy7vb56W0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# connect to Google drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fk5CAFIn6I3D",
        "colab_type": "code",
        "outputId": "4526171c-ab40-40e2-cd4e-8bf4e18d91e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "! ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U8yE6_sA8a2P",
        "colab_type": "code",
        "outputId": "1409fee4-74e2-4977-a660-5eb84c66abfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "! ls gdrive/'My Drive'/NLPProject"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DataExploration.ipynb\t\t songdata.csv\n",
            "jokes.txt\t\t\t songs10000.txt\n",
            "MedTextGenerationModels.ipynb\t songs1000.txt\n",
            "ModelEvaluation.ipynb\t\t songs25000.txt\n",
            "ModelTrainingOutput\t\t songs5000.txt\n",
            "motivational_quotes.txt\t\t TrainedModels\n",
            "ShortTextGenerationModels.ipynb  trump_tweets.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JzD5Qs813CyH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Character-Level RNNs"
      ]
    },
    {
      "metadata": {
        "id": "TvcIyOoA2Usc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model configuration\n",
        "model_cfg = {\n",
        "    'rnn_size': 128,\n",
        "    'rnn_layers': 4,\n",
        "    'rnn_bidirectional': True,\n",
        "    'max_length': 40,\n",
        "    'max_words': 300,\n",
        "    'dim_embeddings': 100,\n",
        "    'word_level': False,\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': False,\n",
        "    'num_epochs': 10,\n",
        "    'gen_epochs': 2,\n",
        "    'batch_size': 512,\n",
        "    'train_size': 0.8,\n",
        "    'dropout': 0.25,\n",
        "    'max_gen_length': 300,\n",
        "    'validation': True,\n",
        "    'is_csv': False\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y9lbt3CJ3M4U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Song Lyrics"
      ]
    },
    {
      "metadata": {
        "id": "1RyrErwty49Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dir = './gdrive/My Drive/NLPProject/'\n",
        "nums = [1000, 5000, 10000, 25000]\n",
        "files = [dir+'songs'+str(n)+'.txt' for n in nums]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "73Uq0UdOzXBh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ecf57808-33a9-44d3-8c6f-51a7500313da"
      },
      "cell_type": "code",
      "source": [
        "files"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./gdrive/My Drive/NLPProject/songs1000.txt',\n",
              " './gdrive/My Drive/NLPProject/songs5000.txt',\n",
              " './gdrive/My Drive/NLPProject/songs10000.txt',\n",
              " './gdrive/My Drive/NLPProject/songs25000.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "a8ko9a1y44AO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "file = files[i]\n",
        "\n",
        "model_name = 'char_'+'songs'+str(nums[i])\n",
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Xy0mvA430sc",
        "colab_type": "code",
        "outputId": "1816a28e-79c3-45c0-9687-45f48e2c44ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4440
        }
      },
      "cell_type": "code",
      "source": [
        "# ~50 mins to train\n",
        "train_function(\n",
        "    file_path=file,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=train_cfg['batch_size'],\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    max_gen_length=train_cfg['max_gen_length'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=model_cfg['dim_embeddings'],\n",
        "    word_level=model_cfg['word_level'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training new model w/ 4-layer, 128-cell Bidirectional LSTMs\n",
            "Training on 965,830 character sequences.\n",
            "Epoch 1/10\n",
            "1886/1886 [==============================] - 451s 239ms/step - loss: 2.9626 - val_loss: 2.1616\n",
            "Epoch 2/10\n",
            "1886/1886 [==============================] - 444s 236ms/step - loss: 1.7235 - val_loss: 1.4415\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\n",
            "What you won't be the seal  \n",
            "I can't be somebody  \n",
            "I can't be here  \n",
            "I want to know you want to be  \n",
            "I want to see  \n",
            "I want to see  \n",
            "I want to be the way  \n",
            "I want to say to say  \n",
            "I want to see you want to see  \n",
            "I won't want to be the boys  \n",
            "I want you love me  \n",
            "I want to see  \n",
            "I want to be the same\n",
            "\n",
            "a ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba ba b\n",
            "\n",
            "\n",
            "I want to say to say  \n",
            "I want to be a brown  \n",
            "I want to be a clost  \n",
            "I won't want to be the world  \n",
            "I say you see a love  \n",
            "I can't be we stay  \n",
            "I want to see the way  \n",
            "I want to be the world  \n",
            "I want to see you want to see  \n",
            "I can't be so stand  \n",
            "I want to see  \n",
            "I want to say to say  \n",
            "I want to say\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "wish I can't see the good  \n",
            "I love you what you won't find  \n",
            "I will be the door  \n",
            "I know alone  \n",
            "What you went a brown  \n",
            "And me with me a cloud and she's real  \n",
            "I love you can see the droo  \n",
            "I can't be all I see  \n",
            "I want to be  \n",
            "I leave you  \n",
            "I said it got me  \n",
            "I can't get it it love you  \n",
            "I can't g\n",
            "\n",
            "ittle way you see  \n",
            "  \n",
            "Oh you so make me  \n",
            "The world world some we were  \n",
            "I want you see  \n",
            "I don't want you the love  \n",
            "But I'm there we sleep it  \n",
            "To know the world  \n",
            "And shame to she chost  \n",
            "When I want a see  \n",
            "I don't got a looked of me  \n",
            "I know I won't stand  \n",
            "I don't want to make my love  \n",
            "The s\n",
            "\n",
            "ly so let me alone  \n",
            "I know what you worth  \n",
            "The sun we wonder the son  \n",
            "The more to me  \n",
            "I was to never see  \n",
            "I want to be free  \n",
            "Weeze a breaking the celor to leave the tand  \n",
            "Everybody cry  \n",
            "The stater with you  \n",
            "Well I can try  \n",
            "The wind we to see  \n",
            "  \n",
            "The real of fleal  \n",
            "Was a little say and sa\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "e aor lones like me  \n",
            "Plape me name about me  \n",
            "Pumbo)  \n",
            "  \n",
            "Everything I week to Here  \n",
            "(Yes crusse seal at, ry of in the moon to Love  \n",
            "Always has you cra  \n",
            "When we've over you this hice of rom me  \n",
            "We sound in let me up  \n",
            "  \n",
            "I was a shem cry hore from the countnonefuless  \n",
            "Rocked the world  \n",
            "Senk w\n",
            "\n",
            "ike love away.  \n",
            "Bey, here's my nigga, rull  \n",
            "Now I wouldn have it follow  \n",
            "All you could, he's wentry girl  \n",
            "We're feel to see  \n",
            "  \n",
            "Sure these new wine  \n",
            "[Chorus]  \n",
            "I know it assed this head  \n",
            "The breath sure  \n",
            "So says Crying then Irlod in preth about guestin here  \n",
            "And me from the moons two  \n",
            "Then\n",
            "\n",
            "Take me anyworld I beet you serve  \n",
            "That me  \n",
            "[Come]  \n",
            "Time somether none you en us you s  \n",
            "I'm going to for what you really try ansrised  \n",
            "And do you could see  \n",
            "As hear and cheap he bit you worldly  \n",
            "I don't walk out my wront  \n",
            "I hope hey my you there  \n",
            "(We right out break Ready)  \n",
            "Watch with afte\n",
            "\n",
            "Epoch 3/10\n",
            "1886/1886 [==============================] - 444s 235ms/step - loss: 1.3677 - val_loss: 1.3079\n",
            "Epoch 4/10\n",
            "1886/1886 [==============================] - 443s 235ms/step - loss: 1.2564 - val_loss: 1.2499\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            " can see  \n",
            "I want to be the one  \n",
            "I want to stay the station  \n",
            "I want to stay the way  \n",
            "I would have to stay and the world  \n",
            "I want to stay the time  \n",
            "I want to stay and start to the future  \n",
            "And I know that I can do  \n",
            "I can do the state to think of the face  \n",
            "And the stars and the street  \n",
            "The sile\n",
            "\n",
            "arts and the silents and starts  \n",
            "And I know I can see  \n",
            "I want to stay and I like you  \n",
            "I want to stay and I start to stay  \n",
            "I can tell you and I want to stay  \n",
            "I want to see you to stay  \n",
            "I want to show the light  \n",
            "I want to live the world  \n",
            "I want to live the light  \n",
            "I want to let the part of the\n",
            "\n",
            "'m a girl  \n",
            "  \n",
            "I'm gonna do something to stay  \n",
            "I'm gonna go for the stage  \n",
            "I want to see the street  \n",
            "I can change the time  \n",
            "I want to stay to stay and the street  \n",
            "The stars are the street  \n",
            "The way that we want to stay  \n",
            "The way that I was the one  \n",
            "The way that I was the one  \n",
            "I want to let th\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "  \n",
            "And I don't need to know I want to be  \n",
            "I didn't know what I think it's finally  \n",
            "I want to live out, I know you need to stay  \n",
            "I may as the future  \n",
            "I wanna be the one  \n",
            "I know you think it's all the one  \n",
            "I know that I want to stay for the proclement  \n",
            "I know the love of laughter  \n",
            "I can find t\n",
            "\n",
            "The sun that we will never all alone  \n",
            "She thinks that we did to think about of my life  \n",
            "  \n",
            "I'm not like a human could be the things the time  \n",
            "  \n",
            "I was the sound of this way  \n",
            "I won't like to wait for the close  \n",
            "I want to think that I fall  \n",
            "I will always love you  \n",
            "I have to get a game on  \n",
            "  \n",
            "I\n",
            "\n",
            "tupid like no way  \n",
            "  \n",
            "Chorus  \n",
            "How we got to get to get so feeling  \n",
            "I got the guire to say  \n",
            "  \n",
            "I want to stay in the ground  \n",
            "And I don't know the time that I do  \n",
            "The day baby don't tell you so long  \n",
            "  \n",
            "I'm gonna know what you start  \n",
            "I said that I thought I'm about of my feet  \n",
            "I said I know I\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "urning on the garstbird to look and tell the  \n",
            "Custfant politichere, otessf( ey' right it straight)  \n",
            "Gotta do I speak to make life if your world  \n",
            "When on you catch me  \n",
            "  \n",
            "(It will)  \n",
            "Oh, laes, anything, it walks so many asssimb fishes  \n",
            "It's in the lights so ills:  \n",
            "  \n",
            "She just daughter for her t\n",
            "\n",
            "I really your heaven you want your way - waitins for the love,  \n",
            "And along he cry merbine eat nice.  \n",
            "  \n",
            "I might believe it all go the day  \n",
            "  \n",
            "Someone tight when I like you  \n",
            "She said I have no great  \n",
            "Oh the world still trying to be held in still  \n",
            "My girl  \n",
            "That's laugh fight  \n",
            "Just lyin' the day\n",
            "\n",
            "  \n",
            "  \n",
            "When I'm calmi, In the sleep  \n",
            "I'm pullowition, day I cross you,  \n",
            "Dead r. Segale iros  \n",
            "  \n",
            "Music to the time)  \n",
            "She's got a control! (sound)  \n",
            "(Yes your cry close)  \n",
            "(I'm, two magic  \n",
            "All to die  \n",
            "  \n",
            "Super cours  \n",
            "I got a lot 'bouse, she was your hope  \n",
            "But there's nothing I like you like a b\n",
            "\n",
            "Epoch 5/10\n",
            " 921/1886 [=============>................] - ETA: 3:29 - loss: 1.1843"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1N8GRW9u0CEj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! cp char_songs1000_config.json ./gdrive/'My Drive'/NLPProject/\n",
        "! cp char_songs1000_vocab.json ./gdrive/'My Drive'/NLPProject/\n",
        "! cp char_songs1000_weights.hdf5 ./gdrive/'My Drive'/NLPProject/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "vN5JuIttSOzd"
      },
      "cell_type": "markdown",
      "source": [
        "## Word-Level RNNs"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SRXbdrn4SOze",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model configuration\n",
        "model_cfg = {\n",
        "    'rnn_size': 128,\n",
        "    'rnn_layers': 4,\n",
        "    'rnn_bidirectional': True,\n",
        "    'max_length': 10,\n",
        "    'max_words': 10000,\n",
        "    'dim_embeddings': 100,\n",
        "    'word_level': True,\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': False,\n",
        "    'num_epochs': 50,\n",
        "    'gen_epochs': 5,\n",
        "    'batch_size': 512,\n",
        "    'train_size': 0.8,\n",
        "    'dropout': 0.25,\n",
        "    'max_gen_length': 80,\n",
        "    'validation': True,\n",
        "    'is_csv': False\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-B81V_sHorx8"
      },
      "cell_type": "markdown",
      "source": [
        "### Song Lyrics"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FDfTxnbKoryE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "file = files[i]\n",
        "\n",
        "model_name = 'char_'+'songs'+str(nums[i])\n",
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7msUqnkVoryJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ~30 mins to train\n",
        "train_function(\n",
        "    file_path=file,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=train_cfg['batch_size'],\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    max_gen_length=train_cfg['max_gen_length'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=model_cfg['dim_embeddings'],\n",
        "    word_level=model_cfg['word_level'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xTdiG1_woryR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! cp word_songs1000_config.json ./gdrive/'My Drive'/NLPProject/\n",
        "! cp word_songs1000_vocab.json ./gdrive/'My Drive'/NLPProject/\n",
        "! cp word_songs1000_weights.hdf5 ./gdrive/'My Drive'/NLPProject/"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}