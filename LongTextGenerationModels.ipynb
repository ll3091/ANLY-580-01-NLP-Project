{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LongTextGenerationModels.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ll3091/ANLY-580-01-NLP-Project/blob/master/LongTextGenerationModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "mrB_G9Ab1QR2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# NLP Project: Text Generation Model Training"
      ]
    },
    {
      "metadata": {
        "id": "PtS7V74X1VaL",
        "colab_type": "code",
        "outputId": "b9f3f188-dc8e-438e-c65e-eea066486592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "# source https://github.com/minimaxir/textgenrnn\n",
        "! pip install textgenrnn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textgenrnn in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from textgenrnn) (2.8.0)\n",
            "Requirement already satisfied: keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from textgenrnn) (2.2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from textgenrnn) (0.19.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->textgenrnn) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py->textgenrnn) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.5->textgenrnn) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.5->textgenrnn) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.5->textgenrnn) (1.0.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.5->textgenrnn) (1.0.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3QC0MFkv2RJ6",
        "colab_type": "code",
        "outputId": "1098a603-0cd8-4d2e-da99-93c75464b72a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from textgenrnn import textgenrnn\n",
        "from google.colab import drive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "l-aqy7vb56W0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# connect to Google drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fk5CAFIn6I3D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U8yE6_sA8a2P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! ls gdrive/'My Drive'/NLPProject"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JzD5Qs813CyH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Character-Level RNNs"
      ]
    },
    {
      "metadata": {
        "id": "TvcIyOoA2Usc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model configuration\n",
        "model_cfg = {\n",
        "    'rnn_size': 128,\n",
        "    'rnn_layers': 4,\n",
        "    'rnn_bidirectional': True,\n",
        "    'max_length': 40,\n",
        "    'max_words': 300,\n",
        "    'dim_embeddings': 100,\n",
        "    'word_level': False,\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': False,\n",
        "    'num_epochs': 10,\n",
        "    'gen_epochs': 2,\n",
        "    'batch_size': 512,\n",
        "    'train_size': 0.8,\n",
        "    'dropout': 0.25,\n",
        "    'max_gen_length': 150,\n",
        "    'validation': True,\n",
        "    'is_csv': False\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y9lbt3CJ3M4U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Conference Paper Abstracts"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "GpCxwNQNx1u2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file = './gdrive/My Drive/NLPProject/abstracts.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0ol0b6xrx1vC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "81d07317-ec73-4abf-ad5f-72fe2d114c15"
      },
      "cell_type": "code",
      "source": [
        "# ~2.5 hours to train\n",
        "model_name = 'char_abstracts'\n",
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path=file,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=train_cfg['batch_size'],\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    max_gen_length=train_cfg['max_gen_length'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=model_cfg['dim_embeddings'],\n",
        "    word_level=model_cfg['word_level'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training new model w/ 4-layer, 128-cell Bidirectional LSTMs\n",
            "Training on 1,123,185 character sequences.\n",
            "Epoch 1/10\n",
            " 656/2193 [=======>......................] - ETA: 5:49 - loss: 3.2143"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qp92L4rKx1vI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! cp char_abstracts_config.json ./gdrive/'My Drive'/NLPProject/\n",
        "! cp char_abstracts_vocab.json ./gdrive/'My Drive'/NLPProject/\n",
        "! cp char_abstracts_weights.hdf5 ./gdrive/'My Drive'/NLPProject/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MbHB02wGW5VT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Conference Papers"
      ]
    },
    {
      "metadata": {
        "id": "NpqZDK4JYBcK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file = './gdrive/My Drive/NLPProject/papers.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ddqcjNHFYB86",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ~x hours to train\n",
        "model_name = 'char_papers'\n",
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path=file,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=train_cfg['batch_size'],\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    max_gen_length=train_cfg['max_gen_length'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=model_cfg['dim_embeddings'],\n",
        "    word_level=model_cfg['word_level'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GI-z-JbwbnaK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! cp char_papers_config.json ./gdrive/'My Drive'/NLPProject/\n",
        "! cp char_papers_vocab.json ./gdrive/'My Drive'/NLPProject/\n",
        "! cp char_papers_weights.hdf5 ./gdrive/'My Drive'/NLPProject/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "vN5JuIttSOzd"
      },
      "cell_type": "markdown",
      "source": [
        "## Word-Level RNNs"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SRXbdrn4SOze",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model configuration\n",
        "model_cfg = {\n",
        "    'rnn_size': 128,\n",
        "    'rnn_layers': 4,\n",
        "    'rnn_bidirectional': True,\n",
        "    'max_length': 10,\n",
        "    'max_words': 10000,\n",
        "    'dim_embeddings': 100,\n",
        "    'word_level': True,\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': False,\n",
        "    'num_epochs': 50,\n",
        "    'gen_epochs': 5,\n",
        "    'batch_size': 512,\n",
        "    'train_size': 0.8,\n",
        "    'dropout': 0.25,\n",
        "    'max_gen_length': 80,\n",
        "    'validation': True,\n",
        "    'is_csv': False\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-B81V_sHorx8"
      },
      "cell_type": "markdown",
      "source": [
        "### Conference Paper Abstracts"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bMxSlE16yQMF",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file = './gdrive/My Drive/NLPProject/abstracts.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Q-I3MvJjyQMQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ~ 1 hour to train\n",
        "model_name = 'word_abstracts'\n",
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path=file,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=train_cfg['batch_size'],\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    max_gen_length=train_cfg['max_gen_length'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=model_cfg['dim_embeddings'],\n",
        "    word_level=model_cfg['word_level'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fPqTqfJKyQMa",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! cp word_abstracts_config.json ./gdrive/'My Drive'/NLPProject/\n",
        "! cp word_abstracts_vocab.json ./gdrive/'My Drive'/NLPProject/\n",
        "! cp word_abstracts_weights.hdf5 ./gdrive/'My Drive'/NLPProject/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E-tNYQo9XE87",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Conference Papers"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wqE8k-bbbbvZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file = './gdrive/My Drive/NLPProject/papers.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bs5ds9Knbbvj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ~ 1 hour to train\n",
        "model_name = 'word_papers'\n",
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path=file,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=train_cfg['batch_size'],\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    max_gen_length=train_cfg['max_gen_length'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=model_cfg['dim_embeddings'],\n",
        "    word_level=model_cfg['word_level'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pcp4gG8dbem6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! cp word_papers_config.json ./gdrive/'My Drive'/NLPProject/\n",
        "! cp word_papers_vocab.json ./gdrive/'My Drive'/NLPProject/\n",
        "! cp word_papers_weights.hdf5 ./gdrive/'My Drive'/NLPProject/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JrZSlxDxanjl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}